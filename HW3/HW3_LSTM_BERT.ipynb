{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "u3wugeOHW-AV",
    "outputId": "7979e6ad-bff3-4493-c0e7-a9666383f9ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\trekc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9XIrxSmW-AX"
   },
   "source": [
    "# Скачиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ep1FB3IBW-AY",
    "outputId": "ed833b2b-3b1a-492a-d9a3-ad845a9074c0"
   },
   "outputs": [],
   "source": [
    "#!python -m wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qmzaEwy9W-Ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>law</td>\n",
       "      <td>Может ли срочник перевестись на контракт после...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>law</td>\n",
       "      <td>часть 1 статья 158 похитил телефон</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237774</th>\n",
       "      <td>relax</td>\n",
       "      <td>елку нарядили? =)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237775</th>\n",
       "      <td>law</td>\n",
       "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237776</th>\n",
       "      <td>food</td>\n",
       "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237777</th>\n",
       "      <td>food</td>\n",
       "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237778</th>\n",
       "      <td>business</td>\n",
       "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237779 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
       "1            law  Может ли срочник перевестись на контракт после...\n",
       "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
       "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
       "4            law                 часть 1 статья 158 похитил телефон\n",
       "...          ...                                                ...\n",
       "237774     relax                                  елку нарядили? =)\n",
       "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
       "237776      food  Попробовала варить рис с половиной кубика для ...\n",
       "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
       "237778  business  Подскажите какие риски бывают в семье среднест...\n",
       "\n",
       "[237779 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('answers_subsample.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "90tXLjfsW-Aj",
    "outputId": "5a41f708-1102-49c7-a38f-795783ccdd81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "law         29.793211\n",
       "relax       22.016242\n",
       "business    19.309527\n",
       "food        18.367055\n",
       "love        10.513965\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category.value_counts() * 100 / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfHbifWIW-Al"
   },
   "source": [
    "# Предобученные эмбеддинги\n",
    "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
    "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
    "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "PVhCzM3LW-Al",
    "outputId": "7b800ec8-bcad-4859-f110-2ac5ddb07f0e"
   },
   "outputs": [],
   "source": [
    "#!python -m wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M0lwyZUFW-Ap"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QQpX51Y4W-Aq"
   },
   "outputs": [],
   "source": [
    "# потом можете добавить свою предобработку\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HyI2erCDW-Ar",
    "outputId": "0e1fe01d-03f8-4073-b646-53f1a0834d90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 237779/237779 [00:02<00:00, 111944.07it/s]\n"
     ]
    }
   ],
   "source": [
    "word2freq = {}\n",
    "lengths = []\n",
    "\n",
    "for text in tqdm(data.text):\n",
    "    \n",
    "    words = process_text(text)\n",
    "    \n",
    "    lengths.append(len(words))\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word in word2freq:\n",
    "            word2freq[word] += 1\n",
    "        else:\n",
    "            word2freq[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FGzDm0ptW-At"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "iZBR-aYDW-Av",
    "outputId": "940b9a8b-91a9-4cdb-f79e-bcd0016e6958"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trekc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Распределение длин слов в текстах'}, xlabel='Длина предложения', ylabel='Доля'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.title('Распределение длин слов в текстах')\n",
    "plt.xlabel('Длина предложения')\n",
    "plt.ylabel('Доля')\n",
    "sns.distplot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OBzmPqXIW-Aw",
    "outputId": "e4430b5f-2d2a-4ac9-fc1a-fa194edd7645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_threshold = 32\n",
    "lower_threshold = 3\n",
    "\n",
    "correct_percent = len([sent_len for sent_len in lengths \n",
    "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
    "\n",
    "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "GbSer_0bW-Ay",
    "outputId": "d71619df-f68b-42a8-d851-3c909ceb6370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152179"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "szg6XD3EW-Az",
    "outputId": "f41121aa-cbb5-426b-b7bb-8f21b1822bd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'114332 слов, которые встречались 3 и менее раз'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZbOg0FqW-A1"
   },
   "source": [
    "# Читаем файл с эмбеддингами\n",
    "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
    "Поэтому прочитаем только те слова, которые мы знаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "T1Yx_qr-W-A2"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "BLEgfnaWW-A4",
    "outputId": "05846f70-6229-4df2-bcd5-68cc08e0d010",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read word2vec: 100%|██████████████████████████████████████████████████████| 2000000/2000000 [00:59<00:00, 33625.54it/s]\n"
     ]
    }
   ],
   "source": [
    "word2index = {'PAD': 0}\n",
    "vectors = []\n",
    "    \n",
    "word2vec_file = open('cc.ru.300.vec', encoding='utf-8')\n",
    "    \n",
    "n_words, embedding_dim = word2vec_file.readline().split()\n",
    "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
    "\n",
    "# Zero vector for PAD\n",
    "vectors.append(np.zeros((1, embedding_dim)))\n",
    "\n",
    "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
    "\n",
    "while True:\n",
    "\n",
    "    line = word2vec_file.readline().strip()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "        \n",
    "    current_parts = line.split()\n",
    "\n",
    "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
    "    \n",
    "    if current_word in word2freq:\n",
    "\n",
    "        word2index[current_word] = len(word2index)\n",
    "        current_vectors = current_parts[-embedding_dim:]\n",
    "\n",
    "        current_vectors = np.array(list(map(float, current_vectors)))\n",
    "        current_vectors = np.expand_dims(current_vectors, 0)\n",
    "\n",
    "        vectors.append(current_vectors)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "word2vec_file.close()\n",
    "\n",
    "vectors = np.concatenate(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AYJMzgpnW-A7",
    "outputId": "4fec5db6-fca6-42a2-93da-be988702d797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117619"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "KE06fafiW-A8",
    "outputId": "d6c87428-4474-4275-f300-d246364d7865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы не знаем 2.50 % слов в датасете\n",
      "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
      "В среднем каждое встречается 1.98 раз\n",
      "\n",
      "Топ 5 невошедших слов:\n",
      "??? с количеством вхождениий - 3641\n",
      "?? с количеством вхождениий - 2448\n",
      "!!! с количеством вхождениий - 2214\n",
      "?) с количеством вхождениий - 2069\n",
      "\"? с количеством вхождениий - 1429\n"
     ]
    }
   ],
   "source": [
    "unk_words = [word for word in word2freq if word not in word2index]\n",
    "unk_counts = [word2freq[word] for word in unk_words]\n",
    "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
    "\n",
    "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
    "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
    "\n",
    "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
    "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
    "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
    "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
    "print()\n",
    "print('Топ 5 невошедших слов:')\n",
    "\n",
    "for i in range(5):\n",
    "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NX5HHDOW-BO"
   },
   "source": [
    "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKr22rklW-BP"
   },
   "source": [
    "По умолчанию LSTM принимает данные с такой размерностью:\n",
    "```python\n",
    "(seq_len, batch, input_size)\n",
    "```\n",
    "Сделано это с целью оптимизации на более низком уровне.  \n",
    "Мы оперируем такими объектами:\n",
    "```python\n",
    "(batch, seq_len, input_size)\n",
    "```\n",
    "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
    "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
    "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bny8SvCgW-BQ"
   },
   "source": [
    "- 128 - размер батча\n",
    "- 64 - количество слов\n",
    "- 1024 - эмбеддинг слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vc-bLok2W-BQ"
   },
   "outputs": [],
   "source": [
    "# # первый способ\n",
    "# lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
    "\n",
    "# pred, mem = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OHpit-1tW-BR",
    "outputId": "e33f0f23-f029-4e7b-b1ff-d3b12276db82"
   },
   "outputs": [],
   "source": [
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru_WzGSJW-BS"
   },
   "outputs": [],
   "source": [
    "# lstm = torch.nn.LSTM(1024, 512)\n",
    "\n",
    "# меняем размерность batch и seq_len местами\n",
    "# x_transposed = x.transpose(0, 1)\n",
    "# pred_transposed, mem = lstm(x_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NHdBavTWW-BT",
    "outputId": "ba454a8b-fec7-402f-a7a1-c4f9f9556e6d"
   },
   "outputs": [],
   "source": [
    "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
    "# pred_transposed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Rcxv55j7W-BV",
    "outputId": "f560450f-75bf-4397-d9f0-f88e3d06705c"
   },
   "outputs": [],
   "source": [
    "# просто транспонируем еще раз\n",
    "# pred = pred_transposed.transpose(0, 1)\n",
    "# pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmJt6cqkW-BW"
   },
   "source": [
    "## Conv1d & MaxPool1d\n",
    "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
    "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
    "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
    "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
    "Ожидается такая размерность:\n",
    "```python\n",
    "(batch, input_size, seq_len)\n",
    "```\n",
    "Мы все еще хоти подавать такую размерность:\n",
    "```python\n",
    "(batch, seq_len, input_size)\n",
    "```\n",
    "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TyM8Xl24W-BX",
    "outputId": "2a5512ca-bc14-43f1-804b-e71df3a7ad7e"
   },
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grPNMjEZW-BY"
   },
   "source": [
    "- 128 - размер батча\n",
    "- 64 - количество слов\n",
    "- 1024 - эмбеддинг слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btJ-ApiOW-BY"
   },
   "outputs": [],
   "source": [
    "# in_channels - размер входных эмбеддингов\n",
    "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
    "# kernel_size - размер окна/н-граммы\n",
    "# cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIYff7YyW-Bb"
   },
   "outputs": [],
   "source": [
    "# выпадет ошибка, посмотрите какая\n",
    "# pred = cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "7tVn6YKLW-Bd",
    "outputId": "7a1a5f4c-b44f-4ed6-f90c-a9d00f78dfe6"
   },
   "outputs": [],
   "source": [
    "# x_transposed = x.transpose(1, 2)\n",
    "# x_transposed.shape\n",
    "# перевели в (batch, input_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2N4w6-iWW-Be",
    "outputId": "bf29af13-5bd4-4882-f60f-b01575b100e8"
   },
   "outputs": [],
   "source": [
    "# pred_transposed = cnn(x_transposed)\n",
    "# pred_transposed.shape\n",
    "# осталась разрмерность (batch, output_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "7-C3_phaW-Bf",
    "outputId": "2ce7a78f-5492-404a-aeb5-2911386734d4"
   },
   "outputs": [],
   "source": [
    "# переведем обратно в (batch, seq_len, input_size)\n",
    "# pred = pred_transposed.transpose(1, 2)\n",
    "# pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stBQ3yhqW-Bi"
   },
   "source": [
    "# Подготовим данные в DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vPX_m5M4W-Bi"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hV76BdN0W-Bj",
    "outputId": "befb4dd0-0df1-4ada-fe1d-dae478226f35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'UNK' in word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "INB_dPAnW-Bk",
    "outputId": "8bb90efa-4c9c-4908-c872-393906ed8619"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>law</td>\n",
       "      <td>Может ли срочник перевестись на контракт после...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>law</td>\n",
       "      <td>часть 1 статья 158 похитил телефон</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text\n",
       "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
       "1       law  Может ли срочник перевестись на контракт после...\n",
       "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
       "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
       "4       law                 часть 1 статья 158 похитил телефон"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qv1mKAeW-Bl"
   },
   "source": [
    "# Замапим категории в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iHeFzZe1W-Bl"
   },
   "outputs": [],
   "source": [
    "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "X3x9QhXYW-Bn",
    "outputId": "0a4dff58-d739-4847-f818-c3e0d321e78a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ef--8SWbW-Bo"
   },
   "outputs": [],
   "source": [
    "data.category = data.category.map(cat_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc48ALg_W-Bp"
   },
   "source": [
    "# Читалка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFIQEv6nvE4c"
   },
   "source": [
    "## Что происходит ниже\n",
    "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
    "1. Загружаем данные:\n",
    "    1. Проходимся по датасету\n",
    "    1. Предобрабатываем каждый текст в датасете\n",
    "    1. Индексируем его\n",
    "    1. Паддим до нужной длины\n",
    "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZkX8SC_sW-Bp"
   },
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token]\n",
    "        \n",
    "        self.load(x_data, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        # Место для вашей предобработки\n",
    "        \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for text in data_iterator:\n",
    "            \n",
    "            words = self.process_text(text)\n",
    "            \n",
    "            indexed_words = self.indexing(words)\n",
    "            self.x_data.append(indexed_words)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "\n",
    "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
    "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
    "        # поэтому просто выбрасываем наши неизветсные слова\n",
    "        \n",
    "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
    "    \n",
    "    def padding(self, sequence):\n",
    "        \n",
    "        # Ограничить длину self.sequence_length\n",
    "        # если длина меньше максимально - западить\n",
    "        if len(sequence)< self.sequence_length:\n",
    "            add_pad = self.sequence_length - len(sequence)\n",
    "            return sequence+[self.pad_index]*add_pad\n",
    "        else:\n",
    "            return sequence[:self.sequence_length]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x)\n",
    "        x = torch.Tensor(x).long()\n",
    "        \n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "R3WW8V9lyLm0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Lnc2nD8gW-Br",
    "outputId": "d72654f9-7a85-49a6-e0c2-429b5db04c4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|█████████████████████████████████████████████████████████| 214001/214001 [00:02<00:00, 92881.89it/s]\n",
      "Loading data: 100%|██████████████████████████████████████████████████████████| 23778/23778 [00:00<00:00, 103203.19it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
    "\n",
    "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dGeftxdgW-Br"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "for x, y in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "nNkGQffBW-Bs",
    "outputId": "77e1ecb5-4bdc-414d-fb89-b7650ed25fba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13208, 10280,   227,  ...,     0,     0,     0],\n",
       "        [ 2285,     8, 21589,  ...,     0,     0,     0],\n",
       "        [  710,  4339, 10746,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [10015,  1882,     1,  ...,     0,     0,     0],\n",
       "        [ 6811,     1,    26,  ...,     0,     0,     0],\n",
       "        [  185,    21, 24775,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "fxUk4nGcW-Bt",
    "outputId": "bae977fd-25ef-4fd7-c451-402e8ea287a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 3, 3, 4, 1, 1, 1, 1, 3, 1, 1, 0, 3, 1, 1, 3, 3, 0, 0, 1, 4, 0, 1,\n",
       "        3, 0, 0, 0, 1, 4, 4, 2, 4, 2, 4, 2, 1, 3, 3, 4, 2, 4, 0, 1, 1, 1, 2, 3,\n",
       "        0, 0, 1, 4, 4, 1, 0, 3, 1, 3, 4, 4, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy0dkkTIW-Bw"
   },
   "source": [
    "# Обучить нейронку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3wwkxZm1vE43"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class model_with_att(torch.nn.Module):\n",
    "    def __init__(self, matrix_w, n, lstm_size, tripple_linear_size, cnn_outsize, inner_linear_size): #n - количетсво категорий\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.n = n\n",
    "\n",
    "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
    "\n",
    "        self.LSTM = lstm = nn.LSTM(input_size=matrix_w.shape[1], hidden_size=lstm_size,\n",
    "                          num_layers=2, dropout=0.1, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
    "        self.q_proj = nn.Linear(lstm_size*2, tripple_linear_size)\n",
    "        self.k_proj = nn.Linear(lstm_size*2, tripple_linear_size)\n",
    "        self.v_proj = nn.Linear(lstm_size*2, tripple_linear_size)\n",
    "\n",
    "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
    "        \n",
    "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
    "        self.cnn_3gr =  nn.Conv1d(in_channels=tripple_linear_size, out_channels=cnn_outsize, kernel_size=3)\n",
    "        self.cnn_4gr = nn.Conv1d(in_channels=tripple_linear_size, out_channels=cnn_outsize, kernel_size=4)\n",
    "        self.cnn_5gr = nn.Conv1d(in_channels=tripple_linear_size, out_channels=cnn_outsize, kernel_size=5)\n",
    "        \n",
    "        # сверху накидываем два полносвязных слоя для классификации\n",
    "        self.linear_1 = nn.Linear(3*cnn_outsize, inner_linear_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(inner_linear_size, out_features=n) \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #примените эмбеддинги\n",
    "        x_emb = self.emb_layer(x)\n",
    "        # транспонируйте тензор для лстм как было описано выше\n",
    "        x_emb = x_emb.transpose(0, 1)\n",
    "        \n",
    "        x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, \n",
    "        #нам нужна только эта\n",
    "        x = x.transpose(0, 1)\n",
    "#         print(x.shape)\n",
    "        # транспонируйте обратно\n",
    "\n",
    "        x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
    "        x_k = self.k_proj(x)\n",
    "        x_v = self.v_proj(x)\n",
    "#         print(x_v.shape)\n",
    "        att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) / sqrt(x_emb.shape[2])\n",
    "#         print(att_scores.shape)\n",
    "        # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, \n",
    "        # перед этим одну из матриц обзательно транспонируйте\n",
    "        # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
    "        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
    "        attention_vectors = torch.bmm(att_dist, x_v)\n",
    "#         print(attention_vectors.shape)\n",
    "\n",
    "        x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
    "\n",
    "        x_cnn3 = self.cnn_3gr(x_att)\n",
    "        x_cnn4 = self.cnn_4gr(x_att)\n",
    "        x_cnn5 = self.cnn_5gr(x_att)\n",
    "#         print(x_cnn3.shape)\n",
    "#         print(x_cnn4.shape)\n",
    "#         print(x_cnn5.shape)\n",
    "        \n",
    "        frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
    "        sc, _ = x_cnn4.max(dim= -1,)\n",
    "        thr, _ = x_cnn5.max(dim= -1,)\n",
    "#         print(frst.shape)\n",
    "#         print(sc.shape)\n",
    "#         print(thr.shape)\n",
    "        x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
    "        # пару полносвязных слоев с релу для классификации\n",
    "#         print(x_cat.shape)\n",
    "\n",
    "        x =  self.linear_1(x_cat)\n",
    "        x = self.relu(x)    \n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OZgh4ONx0HvT"
   },
   "outputs": [],
   "source": [
    "n_classes = data.category.unique().shape[0]\n",
    "model = model_with_att(vectors, n_classes, lstm_size=128,\n",
    "                      tripple_linear_size=128, cnn_outsize=60, inner_linear_size=60)\n",
    "model\n",
    "\n",
    "#model #если сделать batch_first=True, то можно не транспонировать батчи\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Vsxw4M2m0m2B"
   },
   "outputs": [],
   "source": [
    "model = model_with_att(vectors, n_classes, lstm_size=256,\n",
    "                      tripple_linear_size=256, cnn_outsize=128, inner_linear_size=256)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "7rUTc0l60pV9",
    "outputId": "ea81b9b3-b1d3-4122-869b-da0592397d76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_foo():\n",
    "    epochs = 10\n",
    "    losses = []\n",
    "    best_test_loss = 10.\n",
    "\n",
    "    test_f1 = []\n",
    "\n",
    "    for n_epoch in range(epochs):\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        test_targets = []\n",
    "        test_pred_class = []\n",
    "\n",
    "        progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
    "\n",
    "            progress_bar.update(x.shape[0])\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for x, y in validation_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                pred = model(x)\n",
    "\n",
    "                pred = pred.cpu()\n",
    "\n",
    "                test_targets.append(y.numpy())\n",
    "                test_pred_class.append(np.argmax(pred, axis=1))\n",
    "\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "        test_targets = np.concatenate(test_targets).squeeze()\n",
    "        test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
    "\n",
    "        f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
    "\n",
    "        test_f1.append(f1)\n",
    "\n",
    "        print()\n",
    "        print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "\n",
    "        print('F1 test - {:.3f}'.format(f1))\n",
    "\n",
    "        # Early stopping:\n",
    "        if mean_test_loss < best_test_loss:\n",
    "            best_test_loss = mean_test_loss\n",
    "        else:\n",
    "            print('Early stopping')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████| 214001/214001 [01:37<00:00, 2194.45it/s, train_loss=0.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.618, test - 0.483\n",
      "F1 test - 0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████| 214001/214001 [01:35<00:00, 2238.15it/s, train_loss=0.459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.473, test - 0.456\n",
      "F1 test - 0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████| 214001/214001 [01:35<00:00, 2229.46it/s, train_loss=0.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.449, test - 0.442\n",
      "F1 test - 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████| 214001/214001 [01:36<00:00, 2222.84it/s, train_loss=0.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.430, test - 0.439\n",
      "F1 test - 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████████████████████████████| 214001/214001 [01:36<00:00, 2228.16it/s, train_loss=0.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.411, test - 0.449\n",
      "F1 test - 0.839\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "training_foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TMaPbh3oWwc"
   },
   "source": [
    "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_aPjTQcR0vm2",
    "outputId": "03d584f8-2f8c-4e0b-ae8e-7112f6624275"
   },
   "outputs": [],
   "source": [
    "for instance in list(tqdm._instances): \n",
    "    tqdm._decr_instances(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка\n",
    "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
    "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
    "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "e5BgHdtW2sO3"
   },
   "outputs": [],
   "source": [
    "model = model_with_att(vectors, n_classes, lstm_size=10,\n",
    "                      tripple_linear_size=64, cnn_outsize=32, inner_linear_size=32)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████| 214001/214001 [00:54<00:00, 3957.15it/s, train_loss=0.567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.817, test - 0.535\n",
      "F1 test - 0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████| 214001/214001 [00:54<00:00, 3953.72it/s, train_loss=0.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.520, test - 0.481\n",
      "F1 test - 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████| 214001/214001 [00:54<00:00, 3937.57it/s, train_loss=0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.484, test - 0.463\n",
      "F1 test - 0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████| 214001/214001 [00:54<00:00, 3948.10it/s, train_loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.468, test - 0.454\n",
      "F1 test - 0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████| 214001/214001 [00:54<00:00, 3954.85it/s, train_loss=0.452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.459, test - 0.449\n",
      "F1 test - 0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████| 214001/214001 [00:53<00:00, 4001.72it/s, train_loss=0.445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.451, test - 0.444\n",
      "F1 test - 0.840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████████████████| 214001/214001 [00:53<00:00, 3972.69it/s, train_loss=0.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.445, test - 0.442\n",
      "F1 test - 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████| 214001/214001 [00:53<00:00, 3971.96it/s, train_loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.440, test - 0.440\n",
      "F1 test - 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████| 214001/214001 [00:51<00:00, 4193.29it/s, train_loss=0.431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.436, test - 0.438\n",
      "F1 test - 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████| 214001/214001 [00:50<00:00, 4231.71it/s, train_loss=0.427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.431, test - 0.436\n",
      "F1 test - 0.844\n"
     ]
    }
   ],
   "source": [
    "training_foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 test - 0.844 - улучшение получено! Из значимого я уменьшил размер лстм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробую ещё что-нибудь для прекола"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_with_att(vectors, n_classes, lstm_size=20,\n",
    "                      tripple_linear_size=64, cnn_outsize=32, inner_linear_size=32)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████| 214001/214001 [01:00<00:00, 3551.69it/s, train_loss=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.741, test - 0.522\n",
      "F1 test - 0.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████| 214001/214001 [00:59<00:00, 3597.51it/s, train_loss=0.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.503, test - 0.480\n",
      "F1 test - 0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████| 214001/214001 [00:57<00:00, 3753.00it/s, train_loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.473, test - 0.459\n",
      "F1 test - 0.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████| 214001/214001 [00:59<00:00, 3570.26it/s, train_loss=0.448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.458, test - 0.450\n",
      "F1 test - 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████| 214001/214001 [00:59<00:00, 3594.07it/s, train_loss=0.437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.447, test - 0.447\n",
      "F1 test - 0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████| 214001/214001 [00:58<00:00, 3664.04it/s, train_loss=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.438, test - 0.442\n",
      "F1 test - 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████| 214001/214001 [01:00<00:00, 3543.90it/s, train_loss=0.425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.431, test - 0.440\n",
      "F1 test - 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████| 214001/214001 [00:58<00:00, 3666.22it/s, train_loss=0.418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.424, test - 0.438\n",
      "F1 test - 0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████| 214001/214001 [00:58<00:00, 3651.23it/s, train_loss=0.411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.418, test - 0.439\n",
      "F1 test - 0.841\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "training_foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробую БЕРТа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.text.values\n",
    "labels = data.category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237779"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=64, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1:   0%|                                                                              | 0/214001 [00:00<?, ?it/s]C:\\Users\\trekc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Epoch 1: 428032it [35:15, 202.37it/s, train_loss=0.461]                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.522, test - 0.439\n",
      "F1 test - 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 428032it [35:20, 201.86it/s, train_loss=0.392]                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.398, test - 0.433\n",
      "F1 test - 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 428032it [34:59, 203.83it/s, train_loss=0.343]                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.335, test - 0.435\n",
      "F1 test - 0.850\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "import random\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "losses = []\n",
    "best_test_loss = 10.\n",
    "\n",
    "test_f1 = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_targets = []\n",
    "    test_pred_class = []\n",
    "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(epoch_i + 1))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        losses.append(loss.item())\n",
    "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
    "        progress_bar.update(x.shape[0])\n",
    "    \n",
    "    progress_bar.close()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        \n",
    "        logits = outputs[0]\n",
    "        logits = logits\n",
    "        label_ids = b_labels\n",
    "        \n",
    "        test_targets.append(b_labels.cpu().numpy())\n",
    "        test_pred_class.append(np.argmax(logits.cpu(), axis=1))\n",
    "        \n",
    "        loss = criterion(logits, label_ids)\n",
    "\n",
    "        test_losses.append(loss.item())\n",
    "\n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "    \n",
    "    test_targets = np.concatenate(test_targets).squeeze()\n",
    "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
    " \n",
    "    \n",
    "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
    "\n",
    "    test_f1.append(f1)\n",
    "\n",
    "    print()\n",
    "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "    print('F1 test - {:.3f}'.format(f1))\n",
    "    \n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "    else:\n",
    "        print('Early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тут второй вариант с оценкой как в тетрадке берта, только Ф1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, pred_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of  6,688.    Elapsed: 0:00:13.\n",
      "  Batch    80  of  6,688.    Elapsed: 0:00:25.\n",
      "  Batch   120  of  6,688.    Elapsed: 0:00:38.\n",
      "  Batch   160  of  6,688.    Elapsed: 0:00:51.\n",
      "  Batch   200  of  6,688.    Elapsed: 0:01:03.\n",
      "  Batch   240  of  6,688.    Elapsed: 0:01:16.\n",
      "  Batch   280  of  6,688.    Elapsed: 0:01:28.\n",
      "  Batch   320  of  6,688.    Elapsed: 0:01:41.\n",
      "  Batch   360  of  6,688.    Elapsed: 0:01:54.\n",
      "  Batch   400  of  6,688.    Elapsed: 0:02:06.\n",
      "  Batch   440  of  6,688.    Elapsed: 0:02:19.\n",
      "  Batch   480  of  6,688.    Elapsed: 0:02:32.\n",
      "  Batch   520  of  6,688.    Elapsed: 0:02:44.\n",
      "  Batch   560  of  6,688.    Elapsed: 0:02:57.\n",
      "  Batch   600  of  6,688.    Elapsed: 0:03:09.\n",
      "  Batch   640  of  6,688.    Elapsed: 0:03:22.\n",
      "  Batch   680  of  6,688.    Elapsed: 0:03:34.\n",
      "  Batch   720  of  6,688.    Elapsed: 0:03:47.\n",
      "  Batch   760  of  6,688.    Elapsed: 0:03:59.\n",
      "  Batch   800  of  6,688.    Elapsed: 0:04:12.\n",
      "  Batch   840  of  6,688.    Elapsed: 0:04:25.\n",
      "  Batch   880  of  6,688.    Elapsed: 0:04:37.\n",
      "  Batch   920  of  6,688.    Elapsed: 0:04:50.\n",
      "  Batch   960  of  6,688.    Elapsed: 0:05:02.\n",
      "  Batch 1,000  of  6,688.    Elapsed: 0:05:15.\n",
      "  Batch 1,040  of  6,688.    Elapsed: 0:05:27.\n",
      "  Batch 1,080  of  6,688.    Elapsed: 0:05:40.\n",
      "  Batch 1,120  of  6,688.    Elapsed: 0:05:52.\n",
      "  Batch 1,160  of  6,688.    Elapsed: 0:06:05.\n",
      "  Batch 1,200  of  6,688.    Elapsed: 0:06:17.\n",
      "  Batch 1,240  of  6,688.    Elapsed: 0:06:30.\n",
      "  Batch 1,280  of  6,688.    Elapsed: 0:06:42.\n",
      "  Batch 1,320  of  6,688.    Elapsed: 0:06:55.\n",
      "  Batch 1,360  of  6,688.    Elapsed: 0:07:08.\n",
      "  Batch 1,400  of  6,688.    Elapsed: 0:07:21.\n",
      "  Batch 1,440  of  6,688.    Elapsed: 0:07:34.\n",
      "  Batch 1,480  of  6,688.    Elapsed: 0:07:46.\n",
      "  Batch 1,520  of  6,688.    Elapsed: 0:07:59.\n",
      "  Batch 1,560  of  6,688.    Elapsed: 0:08:12.\n",
      "  Batch 1,600  of  6,688.    Elapsed: 0:08:25.\n",
      "  Batch 1,640  of  6,688.    Elapsed: 0:08:38.\n",
      "  Batch 1,680  of  6,688.    Elapsed: 0:08:50.\n",
      "  Batch 1,720  of  6,688.    Elapsed: 0:09:03.\n",
      "  Batch 1,760  of  6,688.    Elapsed: 0:09:16.\n",
      "  Batch 1,800  of  6,688.    Elapsed: 0:09:29.\n",
      "  Batch 1,840  of  6,688.    Elapsed: 0:09:41.\n",
      "  Batch 1,880  of  6,688.    Elapsed: 0:09:54.\n",
      "  Batch 1,920  of  6,688.    Elapsed: 0:10:07.\n",
      "  Batch 1,960  of  6,688.    Elapsed: 0:10:19.\n",
      "  Batch 2,000  of  6,688.    Elapsed: 0:10:32.\n",
      "  Batch 2,040  of  6,688.    Elapsed: 0:10:45.\n",
      "  Batch 2,080  of  6,688.    Elapsed: 0:10:58.\n",
      "  Batch 2,120  of  6,688.    Elapsed: 0:11:11.\n",
      "  Batch 2,160  of  6,688.    Elapsed: 0:11:24.\n",
      "  Batch 2,200  of  6,688.    Elapsed: 0:11:37.\n",
      "  Batch 2,240  of  6,688.    Elapsed: 0:11:49.\n",
      "  Batch 2,280  of  6,688.    Elapsed: 0:12:02.\n",
      "  Batch 2,320  of  6,688.    Elapsed: 0:12:14.\n",
      "  Batch 2,360  of  6,688.    Elapsed: 0:12:27.\n",
      "  Batch 2,400  of  6,688.    Elapsed: 0:12:40.\n",
      "  Batch 2,440  of  6,688.    Elapsed: 0:12:53.\n",
      "  Batch 2,480  of  6,688.    Elapsed: 0:13:06.\n",
      "  Batch 2,520  of  6,688.    Elapsed: 0:13:19.\n",
      "  Batch 2,560  of  6,688.    Elapsed: 0:13:31.\n",
      "  Batch 2,600  of  6,688.    Elapsed: 0:13:44.\n",
      "  Batch 2,640  of  6,688.    Elapsed: 0:13:57.\n",
      "  Batch 2,680  of  6,688.    Elapsed: 0:14:10.\n",
      "  Batch 2,720  of  6,688.    Elapsed: 0:14:23.\n",
      "  Batch 2,760  of  6,688.    Elapsed: 0:14:36.\n",
      "  Batch 2,800  of  6,688.    Elapsed: 0:14:49.\n",
      "  Batch 2,840  of  6,688.    Elapsed: 0:15:01.\n",
      "  Batch 2,880  of  6,688.    Elapsed: 0:15:14.\n",
      "  Batch 2,920  of  6,688.    Elapsed: 0:15:27.\n",
      "  Batch 2,960  of  6,688.    Elapsed: 0:15:40.\n",
      "  Batch 3,000  of  6,688.    Elapsed: 0:15:53.\n",
      "  Batch 3,040  of  6,688.    Elapsed: 0:16:06.\n",
      "  Batch 3,080  of  6,688.    Elapsed: 0:16:19.\n",
      "  Batch 3,120  of  6,688.    Elapsed: 0:16:32.\n",
      "  Batch 3,160  of  6,688.    Elapsed: 0:16:46.\n",
      "  Batch 3,200  of  6,688.    Elapsed: 0:16:59.\n",
      "  Batch 3,240  of  6,688.    Elapsed: 0:17:12.\n",
      "  Batch 3,280  of  6,688.    Elapsed: 0:17:25.\n",
      "  Batch 3,320  of  6,688.    Elapsed: 0:17:39.\n",
      "  Batch 3,360  of  6,688.    Elapsed: 0:17:52.\n",
      "  Batch 3,400  of  6,688.    Elapsed: 0:18:05.\n",
      "  Batch 3,440  of  6,688.    Elapsed: 0:18:18.\n",
      "  Batch 3,480  of  6,688.    Elapsed: 0:18:31.\n",
      "  Batch 3,520  of  6,688.    Elapsed: 0:18:44.\n",
      "  Batch 3,560  of  6,688.    Elapsed: 0:18:58.\n",
      "  Batch 3,600  of  6,688.    Elapsed: 0:19:10.\n",
      "  Batch 3,640  of  6,688.    Elapsed: 0:19:23.\n",
      "  Batch 3,680  of  6,688.    Elapsed: 0:19:36.\n",
      "  Batch 3,720  of  6,688.    Elapsed: 0:19:48.\n",
      "  Batch 3,760  of  6,688.    Elapsed: 0:20:01.\n",
      "  Batch 3,800  of  6,688.    Elapsed: 0:20:14.\n",
      "  Batch 3,840  of  6,688.    Elapsed: 0:20:27.\n",
      "  Batch 3,880  of  6,688.    Elapsed: 0:20:39.\n",
      "  Batch 3,920  of  6,688.    Elapsed: 0:20:52.\n",
      "  Batch 3,960  of  6,688.    Elapsed: 0:21:04.\n",
      "  Batch 4,000  of  6,688.    Elapsed: 0:21:17.\n",
      "  Batch 4,040  of  6,688.    Elapsed: 0:21:30.\n",
      "  Batch 4,080  of  6,688.    Elapsed: 0:21:43.\n",
      "  Batch 4,120  of  6,688.    Elapsed: 0:21:56.\n",
      "  Batch 4,160  of  6,688.    Elapsed: 0:22:09.\n",
      "  Batch 4,200  of  6,688.    Elapsed: 0:22:21.\n",
      "  Batch 4,240  of  6,688.    Elapsed: 0:22:34.\n",
      "  Batch 4,280  of  6,688.    Elapsed: 0:22:47.\n",
      "  Batch 4,320  of  6,688.    Elapsed: 0:23:00.\n",
      "  Batch 4,360  of  6,688.    Elapsed: 0:23:13.\n",
      "  Batch 4,400  of  6,688.    Elapsed: 0:23:25.\n",
      "  Batch 4,440  of  6,688.    Elapsed: 0:23:38.\n",
      "  Batch 4,480  of  6,688.    Elapsed: 0:23:51.\n",
      "  Batch 4,520  of  6,688.    Elapsed: 0:24:04.\n",
      "  Batch 4,560  of  6,688.    Elapsed: 0:24:16.\n",
      "  Batch 4,600  of  6,688.    Elapsed: 0:24:29.\n",
      "  Batch 4,640  of  6,688.    Elapsed: 0:24:42.\n",
      "  Batch 4,680  of  6,688.    Elapsed: 0:24:54.\n",
      "  Batch 4,720  of  6,688.    Elapsed: 0:25:07.\n",
      "  Batch 4,760  of  6,688.    Elapsed: 0:25:19.\n",
      "  Batch 4,800  of  6,688.    Elapsed: 0:25:32.\n",
      "  Batch 4,840  of  6,688.    Elapsed: 0:25:45.\n",
      "  Batch 4,880  of  6,688.    Elapsed: 0:25:57.\n",
      "  Batch 4,920  of  6,688.    Elapsed: 0:26:10.\n",
      "  Batch 4,960  of  6,688.    Elapsed: 0:26:22.\n",
      "  Batch 5,000  of  6,688.    Elapsed: 0:26:35.\n",
      "  Batch 5,040  of  6,688.    Elapsed: 0:26:47.\n",
      "  Batch 5,080  of  6,688.    Elapsed: 0:27:00.\n",
      "  Batch 5,120  of  6,688.    Elapsed: 0:27:12.\n",
      "  Batch 5,160  of  6,688.    Elapsed: 0:27:25.\n",
      "  Batch 5,200  of  6,688.    Elapsed: 0:27:38.\n",
      "  Batch 5,240  of  6,688.    Elapsed: 0:27:50.\n",
      "  Batch 5,280  of  6,688.    Elapsed: 0:28:03.\n",
      "  Batch 5,320  of  6,688.    Elapsed: 0:28:15.\n",
      "  Batch 5,360  of  6,688.    Elapsed: 0:28:28.\n",
      "  Batch 5,400  of  6,688.    Elapsed: 0:28:40.\n",
      "  Batch 5,440  of  6,688.    Elapsed: 0:28:53.\n",
      "  Batch 5,480  of  6,688.    Elapsed: 0:29:05.\n",
      "  Batch 5,520  of  6,688.    Elapsed: 0:29:18.\n",
      "  Batch 5,560  of  6,688.    Elapsed: 0:29:30.\n",
      "  Batch 5,600  of  6,688.    Elapsed: 0:29:43.\n",
      "  Batch 5,640  of  6,688.    Elapsed: 0:29:55.\n",
      "  Batch 5,680  of  6,688.    Elapsed: 0:30:08.\n",
      "  Batch 5,720  of  6,688.    Elapsed: 0:30:20.\n",
      "  Batch 5,760  of  6,688.    Elapsed: 0:30:33.\n",
      "  Batch 5,800  of  6,688.    Elapsed: 0:30:46.\n",
      "  Batch 5,840  of  6,688.    Elapsed: 0:30:58.\n",
      "  Batch 5,880  of  6,688.    Elapsed: 0:31:11.\n",
      "  Batch 5,920  of  6,688.    Elapsed: 0:31:23.\n",
      "  Batch 5,960  of  6,688.    Elapsed: 0:31:36.\n",
      "  Batch 6,000  of  6,688.    Elapsed: 0:31:48.\n",
      "  Batch 6,040  of  6,688.    Elapsed: 0:32:01.\n",
      "  Batch 6,080  of  6,688.    Elapsed: 0:32:13.\n",
      "  Batch 6,120  of  6,688.    Elapsed: 0:32:26.\n",
      "  Batch 6,160  of  6,688.    Elapsed: 0:32:38.\n",
      "  Batch 6,200  of  6,688.    Elapsed: 0:32:51.\n",
      "  Batch 6,240  of  6,688.    Elapsed: 0:33:04.\n",
      "  Batch 6,280  of  6,688.    Elapsed: 0:33:16.\n",
      "  Batch 6,320  of  6,688.    Elapsed: 0:33:29.\n",
      "  Batch 6,360  of  6,688.    Elapsed: 0:33:41.\n",
      "  Batch 6,400  of  6,688.    Elapsed: 0:33:54.\n",
      "  Batch 6,440  of  6,688.    Elapsed: 0:34:06.\n",
      "  Batch 6,480  of  6,688.    Elapsed: 0:34:19.\n",
      "  Batch 6,520  of  6,688.    Elapsed: 0:34:32.\n",
      "  Batch 6,560  of  6,688.    Elapsed: 0:34:44.\n",
      "  Batch 6,600  of  6,688.    Elapsed: 0:34:57.\n",
      "  Batch 6,640  of  6,688.    Elapsed: 0:35:09.\n",
      "  Batch 6,680  of  6,688.    Elapsed: 0:35:22.\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:35:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:01:05\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of  6,688.    Elapsed: 0:00:12.\n",
      "  Batch    80  of  6,688.    Elapsed: 0:00:25.\n",
      "  Batch   120  of  6,688.    Elapsed: 0:00:38.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   160  of  6,688.    Elapsed: 0:00:50.\n",
      "  Batch   200  of  6,688.    Elapsed: 0:01:03.\n",
      "  Batch   240  of  6,688.    Elapsed: 0:01:15.\n",
      "  Batch   280  of  6,688.    Elapsed: 0:01:28.\n",
      "  Batch   320  of  6,688.    Elapsed: 0:01:40.\n",
      "  Batch   360  of  6,688.    Elapsed: 0:01:53.\n",
      "  Batch   400  of  6,688.    Elapsed: 0:02:05.\n",
      "  Batch   440  of  6,688.    Elapsed: 0:02:18.\n",
      "  Batch   480  of  6,688.    Elapsed: 0:02:31.\n",
      "  Batch   520  of  6,688.    Elapsed: 0:02:43.\n",
      "  Batch   560  of  6,688.    Elapsed: 0:02:56.\n",
      "  Batch   600  of  6,688.    Elapsed: 0:03:08.\n",
      "  Batch   640  of  6,688.    Elapsed: 0:03:21.\n",
      "  Batch   680  of  6,688.    Elapsed: 0:03:33.\n",
      "  Batch   720  of  6,688.    Elapsed: 0:03:46.\n",
      "  Batch   760  of  6,688.    Elapsed: 0:03:59.\n",
      "  Batch   800  of  6,688.    Elapsed: 0:04:11.\n",
      "  Batch   840  of  6,688.    Elapsed: 0:04:24.\n",
      "  Batch   880  of  6,688.    Elapsed: 0:04:36.\n",
      "  Batch   920  of  6,688.    Elapsed: 0:04:49.\n",
      "  Batch   960  of  6,688.    Elapsed: 0:05:01.\n",
      "  Batch 1,000  of  6,688.    Elapsed: 0:05:14.\n",
      "  Batch 1,040  of  6,688.    Elapsed: 0:05:26.\n",
      "  Batch 1,080  of  6,688.    Elapsed: 0:05:39.\n",
      "  Batch 1,120  of  6,688.    Elapsed: 0:05:51.\n",
      "  Batch 1,160  of  6,688.    Elapsed: 0:06:04.\n",
      "  Batch 1,200  of  6,688.    Elapsed: 0:06:16.\n",
      "  Batch 1,240  of  6,688.    Elapsed: 0:06:29.\n",
      "  Batch 1,280  of  6,688.    Elapsed: 0:06:41.\n",
      "  Batch 1,320  of  6,688.    Elapsed: 0:06:54.\n",
      "  Batch 1,360  of  6,688.    Elapsed: 0:07:06.\n",
      "  Batch 1,400  of  6,688.    Elapsed: 0:07:19.\n",
      "  Batch 1,440  of  6,688.    Elapsed: 0:07:31.\n",
      "  Batch 1,480  of  6,688.    Elapsed: 0:07:44.\n",
      "  Batch 1,520  of  6,688.    Elapsed: 0:07:56.\n",
      "  Batch 1,560  of  6,688.    Elapsed: 0:08:09.\n",
      "  Batch 1,600  of  6,688.    Elapsed: 0:08:21.\n",
      "  Batch 1,640  of  6,688.    Elapsed: 0:08:34.\n",
      "  Batch 1,680  of  6,688.    Elapsed: 0:08:46.\n",
      "  Batch 1,720  of  6,688.    Elapsed: 0:08:58.\n",
      "  Batch 1,760  of  6,688.    Elapsed: 0:09:11.\n",
      "  Batch 1,800  of  6,688.    Elapsed: 0:09:24.\n",
      "  Batch 1,840  of  6,688.    Elapsed: 0:09:36.\n",
      "  Batch 1,880  of  6,688.    Elapsed: 0:09:48.\n",
      "  Batch 1,920  of  6,688.    Elapsed: 0:10:01.\n",
      "  Batch 1,960  of  6,688.    Elapsed: 0:10:13.\n",
      "  Batch 2,000  of  6,688.    Elapsed: 0:10:26.\n",
      "  Batch 2,040  of  6,688.    Elapsed: 0:10:38.\n",
      "  Batch 2,080  of  6,688.    Elapsed: 0:10:51.\n",
      "  Batch 2,120  of  6,688.    Elapsed: 0:11:03.\n",
      "  Batch 2,160  of  6,688.    Elapsed: 0:11:16.\n",
      "  Batch 2,200  of  6,688.    Elapsed: 0:11:28.\n",
      "  Batch 2,240  of  6,688.    Elapsed: 0:11:41.\n",
      "  Batch 2,280  of  6,688.    Elapsed: 0:11:53.\n",
      "  Batch 2,320  of  6,688.    Elapsed: 0:12:06.\n",
      "  Batch 2,360  of  6,688.    Elapsed: 0:12:18.\n",
      "  Batch 2,400  of  6,688.    Elapsed: 0:12:31.\n",
      "  Batch 2,440  of  6,688.    Elapsed: 0:12:43.\n",
      "  Batch 2,480  of  6,688.    Elapsed: 0:12:56.\n",
      "  Batch 2,520  of  6,688.    Elapsed: 0:13:08.\n",
      "  Batch 2,560  of  6,688.    Elapsed: 0:13:21.\n",
      "  Batch 2,600  of  6,688.    Elapsed: 0:13:33.\n",
      "  Batch 2,640  of  6,688.    Elapsed: 0:13:46.\n",
      "  Batch 2,680  of  6,688.    Elapsed: 0:13:58.\n",
      "  Batch 2,720  of  6,688.    Elapsed: 0:14:11.\n",
      "  Batch 2,760  of  6,688.    Elapsed: 0:14:23.\n",
      "  Batch 2,800  of  6,688.    Elapsed: 0:14:36.\n",
      "  Batch 2,840  of  6,688.    Elapsed: 0:14:48.\n",
      "  Batch 2,880  of  6,688.    Elapsed: 0:15:01.\n",
      "  Batch 2,920  of  6,688.    Elapsed: 0:15:13.\n",
      "  Batch 2,960  of  6,688.    Elapsed: 0:15:26.\n",
      "  Batch 3,000  of  6,688.    Elapsed: 0:15:38.\n",
      "  Batch 3,040  of  6,688.    Elapsed: 0:15:51.\n",
      "  Batch 3,080  of  6,688.    Elapsed: 0:16:03.\n",
      "  Batch 3,120  of  6,688.    Elapsed: 0:16:16.\n",
      "  Batch 3,160  of  6,688.    Elapsed: 0:16:28.\n",
      "  Batch 3,200  of  6,688.    Elapsed: 0:16:41.\n",
      "  Batch 3,240  of  6,688.    Elapsed: 0:16:53.\n",
      "  Batch 3,280  of  6,688.    Elapsed: 0:17:06.\n",
      "  Batch 3,320  of  6,688.    Elapsed: 0:17:18.\n",
      "  Batch 3,360  of  6,688.    Elapsed: 0:17:31.\n",
      "  Batch 3,400  of  6,688.    Elapsed: 0:17:43.\n",
      "  Batch 3,440  of  6,688.    Elapsed: 0:17:56.\n",
      "  Batch 3,480  of  6,688.    Elapsed: 0:18:08.\n",
      "  Batch 3,520  of  6,688.    Elapsed: 0:18:20.\n",
      "  Batch 3,560  of  6,688.    Elapsed: 0:18:33.\n",
      "  Batch 3,600  of  6,688.    Elapsed: 0:18:45.\n",
      "  Batch 3,640  of  6,688.    Elapsed: 0:18:58.\n",
      "  Batch 3,680  of  6,688.    Elapsed: 0:19:10.\n",
      "  Batch 3,720  of  6,688.    Elapsed: 0:19:23.\n",
      "  Batch 3,760  of  6,688.    Elapsed: 0:19:35.\n",
      "  Batch 3,800  of  6,688.    Elapsed: 0:19:48.\n",
      "  Batch 3,840  of  6,688.    Elapsed: 0:20:00.\n",
      "  Batch 3,880  of  6,688.    Elapsed: 0:20:13.\n",
      "  Batch 3,920  of  6,688.    Elapsed: 0:20:25.\n",
      "  Batch 3,960  of  6,688.    Elapsed: 0:20:38.\n",
      "  Batch 4,000  of  6,688.    Elapsed: 0:20:50.\n",
      "  Batch 4,040  of  6,688.    Elapsed: 0:21:03.\n",
      "  Batch 4,080  of  6,688.    Elapsed: 0:21:15.\n",
      "  Batch 4,120  of  6,688.    Elapsed: 0:21:27.\n",
      "  Batch 4,160  of  6,688.    Elapsed: 0:21:40.\n",
      "  Batch 4,200  of  6,688.    Elapsed: 0:21:52.\n",
      "  Batch 4,240  of  6,688.    Elapsed: 0:22:05.\n",
      "  Batch 4,280  of  6,688.    Elapsed: 0:22:17.\n",
      "  Batch 4,320  of  6,688.    Elapsed: 0:22:30.\n",
      "  Batch 4,360  of  6,688.    Elapsed: 0:22:42.\n",
      "  Batch 4,400  of  6,688.    Elapsed: 0:22:55.\n",
      "  Batch 4,440  of  6,688.    Elapsed: 0:23:07.\n",
      "  Batch 4,480  of  6,688.    Elapsed: 0:23:20.\n",
      "  Batch 4,520  of  6,688.    Elapsed: 0:23:32.\n",
      "  Batch 4,560  of  6,688.    Elapsed: 0:23:45.\n",
      "  Batch 4,600  of  6,688.    Elapsed: 0:23:57.\n",
      "  Batch 4,640  of  6,688.    Elapsed: 0:24:10.\n",
      "  Batch 4,680  of  6,688.    Elapsed: 0:24:22.\n",
      "  Batch 4,720  of  6,688.    Elapsed: 0:24:34.\n",
      "  Batch 4,760  of  6,688.    Elapsed: 0:24:47.\n",
      "  Batch 4,800  of  6,688.    Elapsed: 0:24:59.\n",
      "  Batch 4,840  of  6,688.    Elapsed: 0:25:12.\n",
      "  Batch 4,880  of  6,688.    Elapsed: 0:25:24.\n",
      "  Batch 4,920  of  6,688.    Elapsed: 0:25:37.\n",
      "  Batch 4,960  of  6,688.    Elapsed: 0:25:49.\n",
      "  Batch 5,000  of  6,688.    Elapsed: 0:26:02.\n",
      "  Batch 5,040  of  6,688.    Elapsed: 0:26:14.\n",
      "  Batch 5,080  of  6,688.    Elapsed: 0:26:27.\n",
      "  Batch 5,120  of  6,688.    Elapsed: 0:26:39.\n",
      "  Batch 5,160  of  6,688.    Elapsed: 0:26:52.\n",
      "  Batch 5,200  of  6,688.    Elapsed: 0:27:04.\n",
      "  Batch 5,240  of  6,688.    Elapsed: 0:27:16.\n",
      "  Batch 5,280  of  6,688.    Elapsed: 0:27:29.\n",
      "  Batch 5,320  of  6,688.    Elapsed: 0:27:41.\n",
      "  Batch 5,360  of  6,688.    Elapsed: 0:27:54.\n",
      "  Batch 5,400  of  6,688.    Elapsed: 0:28:06.\n",
      "  Batch 5,440  of  6,688.    Elapsed: 0:28:19.\n",
      "  Batch 5,480  of  6,688.    Elapsed: 0:28:31.\n",
      "  Batch 5,520  of  6,688.    Elapsed: 0:28:44.\n",
      "  Batch 5,560  of  6,688.    Elapsed: 0:28:56.\n",
      "  Batch 5,600  of  6,688.    Elapsed: 0:29:09.\n",
      "  Batch 5,640  of  6,688.    Elapsed: 0:29:21.\n",
      "  Batch 5,680  of  6,688.    Elapsed: 0:29:34.\n",
      "  Batch 5,720  of  6,688.    Elapsed: 0:29:46.\n",
      "  Batch 5,760  of  6,688.    Elapsed: 0:29:59.\n",
      "  Batch 5,800  of  6,688.    Elapsed: 0:30:11.\n",
      "  Batch 5,840  of  6,688.    Elapsed: 0:30:23.\n",
      "  Batch 5,880  of  6,688.    Elapsed: 0:30:36.\n",
      "  Batch 5,920  of  6,688.    Elapsed: 0:30:48.\n",
      "  Batch 5,960  of  6,688.    Elapsed: 0:31:01.\n",
      "  Batch 6,000  of  6,688.    Elapsed: 0:31:13.\n",
      "  Batch 6,040  of  6,688.    Elapsed: 0:31:26.\n",
      "  Batch 6,080  of  6,688.    Elapsed: 0:31:38.\n",
      "  Batch 6,120  of  6,688.    Elapsed: 0:31:51.\n",
      "  Batch 6,160  of  6,688.    Elapsed: 0:32:03.\n",
      "  Batch 6,200  of  6,688.    Elapsed: 0:32:16.\n",
      "  Batch 6,240  of  6,688.    Elapsed: 0:32:28.\n",
      "  Batch 6,280  of  6,688.    Elapsed: 0:32:41.\n",
      "  Batch 6,320  of  6,688.    Elapsed: 0:32:53.\n",
      "  Batch 6,360  of  6,688.    Elapsed: 0:33:05.\n",
      "  Batch 6,400  of  6,688.    Elapsed: 0:33:18.\n",
      "  Batch 6,440  of  6,688.    Elapsed: 0:33:30.\n",
      "  Batch 6,480  of  6,688.    Elapsed: 0:33:43.\n",
      "  Batch 6,520  of  6,688.    Elapsed: 0:33:55.\n",
      "  Batch 6,560  of  6,688.    Elapsed: 0:34:08.\n",
      "  Batch 6,600  of  6,688.    Elapsed: 0:34:20.\n",
      "  Batch 6,640  of  6,688.    Elapsed: 0:34:33.\n",
      "  Batch 6,680  of  6,688.    Elapsed: 0:34:45.\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:34:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:01:04\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of  6,688.    Elapsed: 0:00:12.\n",
      "  Batch    80  of  6,688.    Elapsed: 0:00:25.\n",
      "  Batch   120  of  6,688.    Elapsed: 0:00:37.\n",
      "  Batch   160  of  6,688.    Elapsed: 0:00:50.\n",
      "  Batch   200  of  6,688.    Elapsed: 0:01:02.\n",
      "  Batch   240  of  6,688.    Elapsed: 0:01:15.\n",
      "  Batch   280  of  6,688.    Elapsed: 0:01:27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   320  of  6,688.    Elapsed: 0:01:40.\n",
      "  Batch   360  of  6,688.    Elapsed: 0:01:52.\n",
      "  Batch   400  of  6,688.    Elapsed: 0:02:04.\n",
      "  Batch   440  of  6,688.    Elapsed: 0:02:17.\n",
      "  Batch   480  of  6,688.    Elapsed: 0:02:29.\n",
      "  Batch   520  of  6,688.    Elapsed: 0:02:42.\n",
      "  Batch   560  of  6,688.    Elapsed: 0:02:54.\n",
      "  Batch   600  of  6,688.    Elapsed: 0:03:07.\n",
      "  Batch   640  of  6,688.    Elapsed: 0:03:19.\n",
      "  Batch   680  of  6,688.    Elapsed: 0:03:32.\n",
      "  Batch   720  of  6,688.    Elapsed: 0:03:44.\n",
      "  Batch   760  of  6,688.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  6,688.    Elapsed: 0:04:09.\n",
      "  Batch   840  of  6,688.    Elapsed: 0:04:22.\n",
      "  Batch   880  of  6,688.    Elapsed: 0:04:34.\n",
      "  Batch   920  of  6,688.    Elapsed: 0:04:47.\n",
      "  Batch   960  of  6,688.    Elapsed: 0:04:59.\n",
      "  Batch 1,000  of  6,688.    Elapsed: 0:05:11.\n",
      "  Batch 1,040  of  6,688.    Elapsed: 0:05:24.\n",
      "  Batch 1,080  of  6,688.    Elapsed: 0:05:36.\n",
      "  Batch 1,120  of  6,688.    Elapsed: 0:05:49.\n",
      "  Batch 1,160  of  6,688.    Elapsed: 0:06:01.\n",
      "  Batch 1,200  of  6,688.    Elapsed: 0:06:14.\n",
      "  Batch 1,240  of  6,688.    Elapsed: 0:06:26.\n",
      "  Batch 1,280  of  6,688.    Elapsed: 0:06:39.\n",
      "  Batch 1,320  of  6,688.    Elapsed: 0:06:51.\n",
      "  Batch 1,360  of  6,688.    Elapsed: 0:07:04.\n",
      "  Batch 1,400  of  6,688.    Elapsed: 0:07:16.\n",
      "  Batch 1,440  of  6,688.    Elapsed: 0:07:29.\n",
      "  Batch 1,480  of  6,688.    Elapsed: 0:07:41.\n",
      "  Batch 1,520  of  6,688.    Elapsed: 0:07:53.\n",
      "  Batch 1,560  of  6,688.    Elapsed: 0:08:06.\n",
      "  Batch 1,600  of  6,688.    Elapsed: 0:08:18.\n",
      "  Batch 1,640  of  6,688.    Elapsed: 0:08:31.\n",
      "  Batch 1,680  of  6,688.    Elapsed: 0:08:43.\n",
      "  Batch 1,720  of  6,688.    Elapsed: 0:08:56.\n",
      "  Batch 1,760  of  6,688.    Elapsed: 0:09:08.\n",
      "  Batch 1,800  of  6,688.    Elapsed: 0:09:21.\n",
      "  Batch 1,840  of  6,688.    Elapsed: 0:09:33.\n",
      "  Batch 1,880  of  6,688.    Elapsed: 0:09:46.\n",
      "  Batch 1,920  of  6,688.    Elapsed: 0:09:58.\n",
      "  Batch 1,960  of  6,688.    Elapsed: 0:10:11.\n",
      "  Batch 2,000  of  6,688.    Elapsed: 0:10:23.\n",
      "  Batch 2,040  of  6,688.    Elapsed: 0:10:35.\n",
      "  Batch 2,080  of  6,688.    Elapsed: 0:10:48.\n",
      "  Batch 2,120  of  6,688.    Elapsed: 0:11:00.\n",
      "  Batch 2,160  of  6,688.    Elapsed: 0:11:13.\n",
      "  Batch 2,200  of  6,688.    Elapsed: 0:11:25.\n",
      "  Batch 2,240  of  6,688.    Elapsed: 0:11:38.\n",
      "  Batch 2,280  of  6,688.    Elapsed: 0:11:50.\n",
      "  Batch 2,320  of  6,688.    Elapsed: 0:12:03.\n",
      "  Batch 2,360  of  6,688.    Elapsed: 0:12:15.\n",
      "  Batch 2,400  of  6,688.    Elapsed: 0:12:28.\n",
      "  Batch 2,440  of  6,688.    Elapsed: 0:12:40.\n",
      "  Batch 2,480  of  6,688.    Elapsed: 0:12:53.\n",
      "  Batch 2,520  of  6,688.    Elapsed: 0:13:05.\n",
      "  Batch 2,560  of  6,688.    Elapsed: 0:13:17.\n",
      "  Batch 2,600  of  6,688.    Elapsed: 0:13:30.\n",
      "  Batch 2,640  of  6,688.    Elapsed: 0:13:42.\n",
      "  Batch 2,680  of  6,688.    Elapsed: 0:13:55.\n",
      "  Batch 2,720  of  6,688.    Elapsed: 0:14:07.\n",
      "  Batch 2,760  of  6,688.    Elapsed: 0:14:20.\n",
      "  Batch 2,800  of  6,688.    Elapsed: 0:14:32.\n",
      "  Batch 2,840  of  6,688.    Elapsed: 0:14:45.\n",
      "  Batch 2,880  of  6,688.    Elapsed: 0:14:57.\n",
      "  Batch 2,920  of  6,688.    Elapsed: 0:15:10.\n",
      "  Batch 2,960  of  6,688.    Elapsed: 0:15:22.\n",
      "  Batch 3,000  of  6,688.    Elapsed: 0:15:35.\n",
      "  Batch 3,040  of  6,688.    Elapsed: 0:15:47.\n",
      "  Batch 3,080  of  6,688.    Elapsed: 0:15:59.\n",
      "  Batch 3,120  of  6,688.    Elapsed: 0:16:12.\n",
      "  Batch 3,160  of  6,688.    Elapsed: 0:16:24.\n",
      "  Batch 3,200  of  6,688.    Elapsed: 0:16:37.\n",
      "  Batch 3,240  of  6,688.    Elapsed: 0:16:49.\n",
      "  Batch 3,280  of  6,688.    Elapsed: 0:17:02.\n",
      "  Batch 3,320  of  6,688.    Elapsed: 0:17:14.\n",
      "  Batch 3,360  of  6,688.    Elapsed: 0:17:27.\n",
      "  Batch 3,400  of  6,688.    Elapsed: 0:17:39.\n",
      "  Batch 3,440  of  6,688.    Elapsed: 0:17:52.\n",
      "  Batch 3,480  of  6,688.    Elapsed: 0:18:04.\n",
      "  Batch 3,520  of  6,688.    Elapsed: 0:18:17.\n",
      "  Batch 3,560  of  6,688.    Elapsed: 0:18:29.\n",
      "  Batch 3,600  of  6,688.    Elapsed: 0:18:42.\n",
      "  Batch 3,640  of  6,688.    Elapsed: 0:18:54.\n",
      "  Batch 3,680  of  6,688.    Elapsed: 0:19:06.\n",
      "  Batch 3,720  of  6,688.    Elapsed: 0:19:19.\n",
      "  Batch 3,760  of  6,688.    Elapsed: 0:19:31.\n",
      "  Batch 3,800  of  6,688.    Elapsed: 0:19:44.\n",
      "  Batch 3,840  of  6,688.    Elapsed: 0:19:56.\n",
      "  Batch 3,880  of  6,688.    Elapsed: 0:20:09.\n",
      "  Batch 3,920  of  6,688.    Elapsed: 0:20:21.\n",
      "  Batch 3,960  of  6,688.    Elapsed: 0:20:34.\n",
      "  Batch 4,000  of  6,688.    Elapsed: 0:20:46.\n",
      "  Batch 4,040  of  6,688.    Elapsed: 0:20:59.\n",
      "  Batch 4,080  of  6,688.    Elapsed: 0:21:11.\n",
      "  Batch 4,120  of  6,688.    Elapsed: 0:21:24.\n",
      "  Batch 4,160  of  6,688.    Elapsed: 0:21:36.\n",
      "  Batch 4,200  of  6,688.    Elapsed: 0:21:48.\n",
      "  Batch 4,240  of  6,688.    Elapsed: 0:22:01.\n",
      "  Batch 4,280  of  6,688.    Elapsed: 0:22:13.\n",
      "  Batch 4,320  of  6,688.    Elapsed: 0:22:26.\n",
      "  Batch 4,360  of  6,688.    Elapsed: 0:22:38.\n",
      "  Batch 4,400  of  6,688.    Elapsed: 0:22:51.\n",
      "  Batch 4,440  of  6,688.    Elapsed: 0:23:03.\n",
      "  Batch 4,480  of  6,688.    Elapsed: 0:23:16.\n",
      "  Batch 4,520  of  6,688.    Elapsed: 0:23:28.\n",
      "  Batch 4,560  of  6,688.    Elapsed: 0:23:41.\n",
      "  Batch 4,600  of  6,688.    Elapsed: 0:23:53.\n",
      "  Batch 4,640  of  6,688.    Elapsed: 0:24:05.\n",
      "  Batch 4,680  of  6,688.    Elapsed: 0:24:18.\n",
      "  Batch 4,720  of  6,688.    Elapsed: 0:24:30.\n",
      "  Batch 4,760  of  6,688.    Elapsed: 0:24:43.\n",
      "  Batch 4,800  of  6,688.    Elapsed: 0:24:55.\n",
      "  Batch 4,840  of  6,688.    Elapsed: 0:25:08.\n",
      "  Batch 4,880  of  6,688.    Elapsed: 0:25:20.\n",
      "  Batch 4,920  of  6,688.    Elapsed: 0:25:33.\n",
      "  Batch 4,960  of  6,688.    Elapsed: 0:25:45.\n",
      "  Batch 5,000  of  6,688.    Elapsed: 0:25:58.\n",
      "  Batch 5,040  of  6,688.    Elapsed: 0:26:10.\n",
      "  Batch 5,080  of  6,688.    Elapsed: 0:26:23.\n",
      "  Batch 5,120  of  6,688.    Elapsed: 0:26:35.\n",
      "  Batch 5,160  of  6,688.    Elapsed: 0:26:47.\n",
      "  Batch 5,200  of  6,688.    Elapsed: 0:27:00.\n",
      "  Batch 5,240  of  6,688.    Elapsed: 0:27:12.\n",
      "  Batch 5,280  of  6,688.    Elapsed: 0:27:25.\n",
      "  Batch 5,320  of  6,688.    Elapsed: 0:27:37.\n",
      "  Batch 5,360  of  6,688.    Elapsed: 0:27:50.\n",
      "  Batch 5,400  of  6,688.    Elapsed: 0:28:02.\n",
      "  Batch 5,440  of  6,688.    Elapsed: 0:28:15.\n",
      "  Batch 5,480  of  6,688.    Elapsed: 0:28:27.\n",
      "  Batch 5,520  of  6,688.    Elapsed: 0:28:40.\n",
      "  Batch 5,560  of  6,688.    Elapsed: 0:28:52.\n",
      "  Batch 5,600  of  6,688.    Elapsed: 0:29:04.\n",
      "  Batch 5,640  of  6,688.    Elapsed: 0:29:17.\n",
      "  Batch 5,680  of  6,688.    Elapsed: 0:29:29.\n",
      "  Batch 5,720  of  6,688.    Elapsed: 0:29:42.\n",
      "  Batch 5,760  of  6,688.    Elapsed: 0:29:54.\n",
      "  Batch 5,800  of  6,688.    Elapsed: 0:30:07.\n",
      "  Batch 5,840  of  6,688.    Elapsed: 0:30:19.\n",
      "  Batch 5,880  of  6,688.    Elapsed: 0:30:32.\n",
      "  Batch 5,920  of  6,688.    Elapsed: 0:30:44.\n",
      "  Batch 5,960  of  6,688.    Elapsed: 0:30:57.\n",
      "  Batch 6,000  of  6,688.    Elapsed: 0:31:09.\n",
      "  Batch 6,040  of  6,688.    Elapsed: 0:31:22.\n",
      "  Batch 6,080  of  6,688.    Elapsed: 0:31:34.\n",
      "  Batch 6,120  of  6,688.    Elapsed: 0:31:46.\n",
      "  Batch 6,160  of  6,688.    Elapsed: 0:31:59.\n",
      "  Batch 6,200  of  6,688.    Elapsed: 0:32:11.\n",
      "  Batch 6,240  of  6,688.    Elapsed: 0:32:24.\n",
      "  Batch 6,280  of  6,688.    Elapsed: 0:32:36.\n",
      "  Batch 6,320  of  6,688.    Elapsed: 0:32:49.\n",
      "  Batch 6,360  of  6,688.    Elapsed: 0:33:01.\n",
      "  Batch 6,400  of  6,688.    Elapsed: 0:33:14.\n",
      "  Batch 6,440  of  6,688.    Elapsed: 0:33:26.\n",
      "  Batch 6,480  of  6,688.    Elapsed: 0:33:39.\n",
      "  Batch 6,520  of  6,688.    Elapsed: 0:33:51.\n",
      "  Batch 6,560  of  6,688.    Elapsed: 0:34:04.\n",
      "  Batch 6,600  of  6,688.    Elapsed: 0:34:16.\n",
      "  Batch 6,640  of  6,688.    Elapsed: 0:34:29.\n",
      "  Batch 6,680  of  6,688.    Elapsed: 0:34:41.\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:34:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:01:04\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, 3):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "QuesT_Homework3_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
